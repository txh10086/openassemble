# FastAPIProject/backend/decomposition.py

import asyncio, json, time
from openai import AsyncOpenAI
from agents import Agent, Runner, OpenAIChatCompletionsModel, set_tracing_disabled

# â€”â€” ç¦ç”¨ tracing â€”â€”
set_tracing_disabled(True)

# â€”â€” OpenAI å®¢æˆ·ç«¯é…ç½® â€”â€”
import os

BASE_URL = "https://cloud.infini-ai.com/maas/v1"
MODEL_NAME = "deepseek-v3"

# ä»ç¯å¢ƒå˜é‡è¯»å– API å¯†é’¥ï¼Œé¿å…åœ¨ä»£ç ä¸­ç¡¬ç¼–ç 
API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise EnvironmentError("OPENAI_API_KEY environment variable not set")

client = AsyncOpenAI(base_url=BASE_URL, api_key=API_KEY)

# â€”â€” èƒŒæ™¯ä¿¡æ¯ â€”â€”
BACKGROUND = """
1. äº§çº¿æ¶æ„ï¼š
   ä¸»/å‰¯é˜€ä½“ä¸Šæ–™å•å…ƒ â†’ æ³¢å½¢å¼¹ç°§å®‰è£…å•å…ƒ â†’ é˜€åº§ã€é˜€æ†ã€é˜€èŠ¯å®‰è£…å•å…ƒ â†’ åŒå¤´èºæŸ±å®‰è£…å•å…ƒ â†’ 
   ç¼ ç»•å«ç‰‡å®‰è£…å•å…ƒ â†’ é˜€ä½“åˆè£…å•å…ƒ â†’ èºæ¯æ‹§ç´§å•å…ƒ â†’ å¡«æ–™å‹è£…å•å…ƒ â†’ æˆå“ä¸‹æ–™å•å…ƒ

2. ç°åœºè®¾å¤‡æ˜ç»†ï¼š
   - ä¸»/å‰¯é˜€ä½“ä¸Šæ–™å•å…ƒï¼š
     â€¢ å€é€Ÿé“¾è¾“é€çº¿åŠæ‰˜ç›˜ç³»ç»Ÿ  
     â€¢ å·¥ä½1é˜»æŒ¡æ°”ç¼¸ã€å·¥ä½1æŠ¬å‡æ°”ç¼¸ã€å·¥ä½1ä¸¤é”€å®šä½æœºæ„  
     â€¢ èŠ‚å¡ Zu20 åä½œæœºå™¨äººï¼ˆä¸»/å‰¯é˜€ä½“ä¸Šæ–™ï¼‰  
     â€¢ å·¥ä¸šç›¸æœºè§†è§‰ç³»ç»Ÿï¼ˆæ¢…å¡æ›¼å¾· ProMï¼Œå¤§è§†é‡ï¼‰
   - æ³¢å½¢å¼¹ç°§å®‰è£…å•å…ƒï¼š
     â€¢ å€é€Ÿé“¾è¾“é€çº¿åŠæ‰˜ç›˜ç³»ç»Ÿ  
     â€¢ å·¥ä½2é˜»æŒ¡æ°”ç¼¸  
     â€¢ ER6-700-SR å››è½´ SCARA æœºå™¨äººï¼ˆæ³¢å½¢å¼¹ç°§å®‰è£…ï¼‰
   - é˜€åº§ã€é˜€æ†ã€é˜€èŠ¯å®‰è£…å•å…ƒï¼š
     â€¢ å€é€Ÿé“¾è¾“é€çº¿åŠæ‰˜ç›˜ç³»ç»Ÿ  
     â€¢ å·¥ä½3é˜»æŒ¡æ°”ç¼¸ã€å·¥ä½3æŠ¬å‡æ°”ç¼¸ã€å·¥ä½4é˜»æŒ¡æ°”ç¼¸ã€å·¥ä½4æŠ¬å‡æ°”ç¼¸ã€å·¥ä½5é˜»æŒ¡æ°”ç¼¸  
     â€¢ èŠ‚å¡ Zu18 åä½œæœºå™¨äººï¼ˆçƒèŠ¯å®‰è£…ã€å¯†å°é˜€åº§å®‰è£…ï¼Œå…·å¤‡å¯æ¢æ‰‹çˆªåº“ï¼‰  
     â€¢ Flexiv Rizon 10 åä½œæœºå™¨äººï¼ˆé˜€æ†å®‰è£…ï¼Œå…·å¤‡å¯æ¢æ‰‹çˆªåº“ï¼‰
   - åŒå¤´èºæŸ±å®‰è£…å•å…ƒï¼š
     â€¢ å€é€Ÿé“¾è¾“é€çº¿åŠæ‰˜ç›˜ç³»ç»Ÿ  
     â€¢ å·¥ä½6é˜»æŒ¡æ°”ç¼¸ã€å·¥ä½6æŠ¬å‡æ°”ç¼¸  
     â€¢ åŒå¤´èºæŸ±æŒ¯åŠ¨ç›˜é€æ–™å™¨  
     â€¢ å·¥ä¸šç›¸æœºè§†è§‰ç³»ç»Ÿï¼ˆæ¢…å¡æ›¼å¾· Nanoï¼‰  
     â€¢ æ‘†åŠ¨æ°”ç¼¸ï¼ˆèºæŸ±ç¿»è½¬ï¼‰ã€å§¿æ€è°ƒæ•´æ°”ç¼¸ï¼ˆèºæŸ±ç«–ç›´ï¼‰  
     â€¢ ä¸‰è½´æœºæ¢°æ‰‹ï¼ˆåŒå¤´èºæŸ±å®‰è£…ï¼‰
   - ç¼ ç»•å«ç‰‡å®‰è£…å•å…ƒï¼š
     â€¢ å€é€Ÿé“¾è¾“é€çº¿åŠæ‰˜ç›˜ç³»ç»Ÿ  
     â€¢ å·¥ä½7é˜»æŒ¡æ°”ç¼¸ã€å·¥ä½7æŠ¬å‡æ°”ç¼¸  
     â€¢ ER6-700-SR å››è½´ SCARA æœºå™¨äººï¼ˆç¼ ç»•å«ç‰‡å®‰è£…ï¼‰  
     â€¢ å«ç‰‡å‹è£…æœºæ„
   - é˜€ä½“åˆè£…å•å…ƒï¼š
     â€¢ å€é€Ÿé“¾è¾“é€çº¿åŠæ‰˜ç›˜ç³»ç»Ÿ  
     â€¢ å·¥ä½8é˜»æŒ¡æ°”ç¼¸ã€å·¥ä½8æŠ¬å‡æ°”ç¼¸  
     â€¢ UR20 åä½œæœºå™¨äººï¼ˆé˜€ä½“åˆè£…ï¼‰
   - èºæ¯æ‹§ç´§å•å…ƒï¼š
     â€¢ å·¥ä½9é˜»æŒ¡æ°”ç¼¸ã€å·¥ä½9é¡¶å‡æ—‹è½¬æœºæ„  
     â€¢ èºæ¯æŒ¯åŠ¨ç›˜é€æ–™å™¨  
     â€¢ ER6-700-SR å››è½´ SCARA æœºå™¨äººï¼ˆèºæ¯ä¾›æ–™ï¼‰  
     â€¢ ä¼ºæœå‹æœºï¼ˆé˜€ä½“å‹ç´§å¤¹æŒï¼‰ã€ä¸‰è½´æœºæ¢°æ‰‹ï¼ˆæ‹§ç´§æ”¯æ’‘ï¼‰ã€æ‹§ç´§æœºï¼ˆèºæ¯æ‹§ç´§è®¾å¤‡ï¼‰
   - å¡«æ–™å‹è£…å•å…ƒï¼š
     â€¢ å€é€Ÿé“¾è¾“é€çº¿åŠæ‰˜ç›˜ç³»ç»Ÿ  
     â€¢ ä¼ºæœå‹æœºï¼ˆå¡«æ–™å‹è£…ï¼‰
   - æˆå“ä¸‹æ–™å•å…ƒï¼š
     â€¢ å€é€Ÿé“¾è¾“é€çº¿åŠæ‰˜ç›˜ç³»ç»Ÿ  
     â€¢ å·¥ä½11é˜»æŒ¡æ°”ç¼¸  
     â€¢ ççŸ³å…­è½´æœºå™¨äººï¼ˆæˆå“ä¸‹æ–™ï¼‰

3. å„å•å…ƒåŠŸèƒ½èƒ½åŠ›ç®€è¿°ï¼š
   - ä¸»/å‰¯é˜€ä½“ä¸Šæ–™å•å…ƒï¼šæ‰˜ç›˜è‡ªåŠ¨è¾“é€ä¸å®šä½ï¼Œæ”¯æŒè§†è§‰æ£€æµ‹å’Œä¸»/å‰¯é˜€ä½“ä¸Šæ–™ã€‚  
   - æ³¢å½¢å¼¹ç°§å®‰è£…å•å…ƒï¼šSCARA æœºå™¨äººé«˜é€Ÿç²¾ç¡®å®Œæˆå¼¹ç°§è£…é…ã€‚  
   - é˜€åº§/é˜€æ†/é˜€èŠ¯å®‰è£…å•å…ƒï¼šåä½œæœºå™¨äººä¸è§†è§‰ç³»ç»Ÿç»“åˆï¼Œå®ç°å¤šç±»éƒ¨ä»¶è‡ªåŠ¨åŒ–ç²¾è£…é…ã€‚  
   - åŒå¤´èºæŸ±å®‰è£…å•å…ƒï¼šæœºæ¢°æ‰‹é…åˆæŒ¯åŠ¨ç›˜ä¸æ°”ç¼¸ï¼Œå®ç°åŒèºæŸ±ç²¾å‡†é€æ–™ä¸å®‰è£…ã€‚  
   - ç¼ ç»•å«ç‰‡å®‰è£…å•å…ƒï¼šSCARA æœºå™¨äººä¸å‹è£…æœºæ„ç»“åˆï¼Œé«˜æ•ˆå®Œæˆå«ç‰‡ç»•è£…ã€‚  
   - é˜€ä½“åˆè£…å•å…ƒï¼šUR20 åä½œæœºå™¨äººå¯å°†ä¸»é˜€ä½“åˆè£…è‡³å‰¯é˜€ä½“ä¸Šã€‚  
   - èºæ¯æ‹§ç´§å•å…ƒï¼šä¼ºæœå‹æœºä¸èºæ¯æ‹§ç´§æœºè”åŠ¨ï¼Œç¡®ä¿ç´§å›ºæ‰­çŸ©å¯æ§ã€å¯é ã€‚  
   - å¡«æ–™å‹è£…å•å…ƒï¼šä¼ºæœå‹æœºç²¾ç¡®å®Œæˆå¡«æ–™å‹è£…ï¼Œä¿è¯å¯†å°æ€§èƒ½ã€‚  
   - æˆå“ä¸‹æ–™å•å…ƒï¼šå…­è½´æœºå™¨äººå®Œæˆæˆå“å¸æ–™ã€‚  
"""

# â€”â€” ä»»åŠ¡åˆ†è§£æ™ºèƒ½ä½“ â€”â€”
agent_TaskDecomposition = Agent(
    name="TaskDecomposition_agent",
    instructions=(
        "ä½ çš„è§’è‰²ï¼šæ§åˆ¶é˜€è£…é…è‡ªåŠ¨çº¿çš„ä»»åŠ¡åˆ†è§£æ™ºèƒ½ä½“ï¼Œæ“…é•¿æ ¹æ®æ•´ä½“è£…é…ä»»åŠ¡åˆ¶å®šåˆç†çš„å·¥åºè®¡åˆ’ã€‚"
        f"\näº§çº¿ç°åœºèƒŒæ™¯ä¿¡æ¯ï¼š{BACKGROUND}"
        "\nä»»åŠ¡ç›®æ ‡ï¼šè¯·å°†ç»™å®šçš„è£…é…ä»»åŠ¡\"è£…é…DN50çƒé˜€\"æ‹†è§£ä¸ºè‹¥å¹²å…¸å‹å·¥åºã€‚æ¯ä¸ªå·¥åºåº”ç‹¬ç«‹æˆæ®µï¼Œæ¸…æ™°å®šä¹‰å…¶åœ¨è£…é…æµç¨‹ä¸­çš„ä½œç”¨ï¼Œç¬¦åˆå®é™…å·¥ä¸šè£…é…é¡ºåºå’Œç°åœºè®¾å¤‡ä½œä¸šèƒ½åŠ›ã€‚"
        "\nä¸“ä¸šè¯­å¢ƒï¼šè£…é…DN50çƒé˜€æ˜¯é˜€é—¨åˆ¶é€ ä¸­çš„ä¸€é¡¹å…¸å‹ä»»åŠ¡ï¼Œæ¶‰åŠå¤šä¸ªé›¶éƒ¨ä»¶ï¼ˆé˜€ä½“ã€é˜€åº§ã€é˜€çƒã€é˜€æ†ã€å¯†å°ä»¶ã€å¼¹ç°§ç­‰ï¼‰çš„é€æ­¥ç»„è£…å’Œæ£€æµ‹ã€‚è¯·å……åˆ†è€ƒè™‘å·¥ä¸šç°åœºçš„å®é™…æµç¨‹å’Œä¸“ä¸šæœ¯è¯­ï¼Œç¡®ä¿å·¥åºåˆ’åˆ†å…¨é¢ä¸”åˆç†ï¼ˆæ¶µç›–ä»é›¶éƒ¨ä»¶å‡†å¤‡ã€å„ç»„ä»¶è£…é…åˆ°æœ€ç»ˆæµ‹è¯•æ£€éªŒçš„ä¸»è¦é˜¶æ®µï¼‰ã€‚"
        "\nè¾“å‡ºæ ¼å¼è¦æ±‚ï¼šä»…è¾“å‡ºJSONï¼ŒåŒ…å«ä»»åŠ¡åç§°å’Œå·¥åºåˆ—è¡¨ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼š"
        "\n- taskï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šæ•´ä½“ä»»åŠ¡åç§°ï¼Œå³ \"è£…é…DN50çƒé˜€\"ã€‚"
        "\n- processesï¼ˆæ•°ç»„ï¼‰ï¼šå·¥åºåˆ—è¡¨ï¼ŒæŒ‰å®é™…é¡ºåºæ’åˆ—ã€‚æ¯ä¸ªå·¥åºç”¨ä¸€ä¸ªJSONå¯¹è±¡è¡¨ç¤ºï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š"
        "\n  - process_idï¼ˆæ•´æ•°ï¼‰ï¼šå·¥åºåºå·ï¼Œä»1å¼€å§‹é€’å¢ã€‚"
        "\n  - nameï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šå·¥åºåç§°ï¼Œç²¾å‡†æ¦‚æ‹¬è¯¥å·¥åºå†…å®¹ã€‚"
        "\n  - descriptionï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šå¯¹è¯¥å·¥åºçš„è¯¦ç»†æè¿°ï¼Œæ¶µç›–è¯¥é˜¶æ®µéœ€å®Œæˆçš„æ“ä½œæˆ–ç›®æ ‡ã€‚"
        "\n  - descriptionï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šå¯¹è¯¥å·¥åºçš„è¯¦ç»†æè¿°ï¼Œæ¶µç›–è¯¥é˜¶æ®µéœ€å®Œæˆçš„æ“ä½œæˆ–ç›®æ ‡ã€‚"
        "\næ ¼å¼ç¤ºä¾‹ï¼šï¼ˆè¯·ä¸¥æ ¼éµå¾ªæ­¤JSONç»“æ„ï¼Œä¸è¦é™„åŠ é¢å¤–è¯´æ˜ï¼‰"
        "```json\n{\n  \"task\": \"è£…é…DN50çƒé˜€\",\n  \"processes\": [\n    {\"process_id\": 1, \"name\": \"å·¥åºåç§°1\", \"description\": \"å·¥åºæè¿°1\"},\n    {\"process_id\": 2, \"name\": \"å·¥åºåç§°2\", \"description\": \"å·¥åºæè¿°2\"}\n  ]\n}```"
    ),
    model=OpenAIChatCompletionsModel(model=MODEL_NAME, openai_client=client),
    tools=[]
)

# â€”â€” å·¥åºåˆ†è§£æ™ºèƒ½ä½“ â€”â€”
agent_ProcessDecomposition = Agent(
    name="ProcessDecompositionIntelligent_agent",
    instructions=(
        "ä½ çš„è§’è‰²ï¼šæ§åˆ¶é˜€è£…é…è‡ªåŠ¨çº¿çš„å·¥åºåˆ†è§£æ™ºèƒ½ä½“ï¼Œæ“…é•¿å°†æŸä¸€é“è£…é…å·¥åºç»†åŒ–ä¸ºå…·ä½“çš„æ“ä½œæ­¥éª¤ã€‚"
        f"\näº§çº¿ç°åœºèƒŒæ™¯ä¿¡æ¯ï¼š{BACKGROUND}"
        "\nä»»åŠ¡ç›®æ ‡ï¼šé’ˆå¯¹ç»™å®šçš„è£…é…å·¥åºï¼ˆä¾‹å¦‚ï¼š\"å®‰è£…é˜€åº§\"ï¼‰ï¼Œå°†å…¶è¿›ä¸€æ­¥åˆ†è§£ä¸ºæœ‰åºçš„å·¥æ­¥åˆ—è¡¨ã€‚æ¯ä¸ªå·¥æ­¥éœ€æ˜ç¡®æè¿°å…·ä½“åŠ¨ä½œã€å‚æ•°è¦æ±‚ã€æ‰§è¡Œé¡ºåºå’Œç›®çš„ï¼Œä½“ç°å®é™…è‡ªåŠ¨åŒ–å·¥ä¸šè£…é…ç»†èŠ‚ã€‚"
        "\nä¸“ä¸šè¯­å¢ƒï¼šé˜€é—¨è£…é…å·¥åºé€šå¸¸åŒ…å«å¤šä¸ªç»†èŠ‚æ­¥éª¤ã€‚ä¾‹å¦‚ï¼Œåœ¨\"å®‰è£…é˜€åº§\"å·¥åºä¸­ï¼Œéœ€è¦å…ˆæ£€æŸ¥é˜€ä½“å’Œé˜€åº§éƒ¨ä»¶çŠ¶å†µï¼Œç„¶åæŒ‰é¡ºåºå®Œæˆé˜€åº§çš„å°±ä½å’Œå›ºå®šç­‰æ“ä½œã€‚è¯·ä½¿ç”¨ä¸“ä¸šä¸”ä¸¥è°¨çš„è¯­è¨€æè¿°æ¯ä¸ªå·¥æ­¥ï¼Œç¡®ä¿ç¬¦åˆå®é™…è£…é…æµç¨‹ï¼ˆåŒ…æ‹¬å®‰å…¨æ£€æŸ¥ã€é›¶ä»¶å®‰è£…ã€å®šä½å›ºå®šã€æ£€æŸ¥éªŒè¯ç­‰ç¯èŠ‚ï¼‰ã€‚"
        "\nè¾“å‡ºæ ¼å¼è¦æ±‚ï¼šä»…è¾“å‡ºJSONï¼ŒåŒ…å«å·¥åºåç§°å’Œæ­¥éª¤åˆ—è¡¨ä¸¤ä¸ªéƒ¨åˆ†ï¼š"
        "\n- processï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šå·¥åºåç§°ï¼Œå³æ‰€éœ€åˆ†è§£çš„å·¥åºï¼ˆä¾‹å¦‚ \"å®‰è£…é˜€åº§\"ï¼‰ã€‚"
        "\n- stepsï¼ˆæ•°ç»„ï¼‰ï¼šå·¥æ­¥åˆ—è¡¨ï¼ŒæŒ‰æ‰§è¡Œå…ˆåé¡ºåºæ’åˆ—ã€‚æ¯ä¸ªå·¥æ­¥ç”¨ä¸€ä¸ªJSONå¯¹è±¡è¡¨ç¤ºï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š"
        "\n  - step_idï¼ˆæ•´æ•°ï¼‰ï¼šå·¥æ­¥åºå·ï¼Œä»1å¼€å§‹é€’å¢ã€‚"
        "\n  - unitï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šå•å…ƒåç§°ï¼Œæ˜ç¡®è¯¥æ­¥æ¶‰åŠåˆ°çš„è£…é…å•å…ƒã€‚"
        "\n  - deviceï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šè®¾å¤‡åç§°ï¼Œæ˜ç¡®è¯¥æ­¥æ¶‰åŠåˆ°çš„è®¾å¤‡ã€‚"
        "\n  - actionï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼šå…·ä½“æ“ä½œæè¿°ï¼Œæ˜ç¡®è¯¥æ­¥è¦æ‰§è¡Œçš„å†…å®¹å’Œç›®æ ‡ã€‚"
        "\næ ¼å¼ç¤ºä¾‹ï¼šï¼ˆè¯·ä¸¥æ ¼éµå¾ªæ­¤JSONç»“æ„ï¼Œä¸è¦è¾“å‡ºé¢å¤–è§£é‡Šï¼‰"
        "```json\n{\n  \"process\": \"ä¸»å‰¯é˜€ä½“ä¸Šæ–™\",\n  \"steps\": [\n    {\"step_id\": 1, \"unit\": \"ä¸»/å‰¯é˜€ä½“ä¸Šæ–™å•å…ƒ\", \"device\": \"å€é€Ÿé“¾è¾“é€çº¿åŠæ‰˜ç›˜ç³»ç»Ÿ\", \"action\": \"æ‰˜ç›˜åˆ°è¾¾å·¥ä½å¹¶åœæ­¢ï¼Œæ¥è¿‘ä¼ æ„Ÿå™¨æ£€æµ‹æ‰˜ç›˜å·²åˆ°ä½\"},\n    {\"step_id\": 2, \"unit\": \"ä¸»/å‰¯é˜€ä½“ä¸Šæ–™å•å…ƒ\", \"device\": \"èŠ‚å¡Zu20åä½œæœºå™¨äºº\", \"action\": \"æŠ“å–ä»»åŠ¡åˆ†é…çš„ä¸»é˜€ä½“\"}\n  ]\n}```"
    ),
    model=OpenAIChatCompletionsModel(model=MODEL_NAME, openai_client=client),
    tools=[]
)

# â€”â€” æ–‡æœ¬æ¸…ç†å‡½æ•° â€”â€”
def clean_markdown(raw: str) -> str:
    """
    ç§»é™¤å¯èƒ½çš„ Markdown ä»£ç å—æ ‡è®° ``` æˆ– ```json
    """
    if raw.startswith("```"):
        lines = raw.splitlines()
        # å»æ‰å¼€å¤´çš„ ``` æˆ– ```json
        if lines and lines[0].startswith("```"):
            lines = lines[1:]
        # å»æ‰ç»“å°¾çš„ ```
        if lines and lines[-1].startswith("```"):
            lines = lines[:-1]
        return "\n".join(lines)
    return raw


# â€”â€” å¹¶è¡Œåˆ†è§£å•ä¸ªå·¥åº â€”â€”
async def decompose_single_process(process_name: str) -> dict:
    """åˆ†è§£å•ä¸ªå·¥åºå¹¶è¿”å›æ­¥éª¤"""
    try:
        # print(f"  - å¼€å§‹åˆ†è§£å·¥åº: {process_name}")  # å‡å°‘æ—¥å¿—å™ªéŸ³
        step_res = await Runner.run(agent_ProcessDecomposition, input=process_name)
        raw_steps = clean_markdown(step_res.final_output or getattr(step_res, 'content', '') or "")
        steps = json.loads(raw_steps).get("steps", [])
        # print(f"  - å®Œæˆåˆ†è§£å·¥åº: {process_name}, å·¥æ­¥æ•°: {len(steps)}")
        return {"name": process_name, "steps": steps}
    except Exception as e:
        print(f"  âœ— åˆ†è§£å·¥åº {process_name} æ—¶å‡ºé”™: {e}")
        return {"name": process_name, "steps": []}


# â€”â€” ç¼“å­˜æœºåˆ¶ â€”â€”
# ç”¨äºå­˜å‚¨æœ€è¿‘çš„åˆ†è§£ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
_result_cache = {}
_cache_lock = asyncio.Lock()  # æ·»åŠ é”ä»¥é¿å…å¹¶å‘é—®é¢˜
_cache_hits = 0  # ç¼“å­˜å‘½ä¸­æ¬¡æ•°ç»Ÿè®¡
_cache_misses = 0  # ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°ç»Ÿè®¡


# â€”â€” ä¸»æµç¨‹ï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼‰ â€”â€”
async def run_full_decomposition(task: str) -> dict:
    """
    å®Œæ•´æ‰§è¡Œï¼šå…ˆåˆ†è§£ä»»åŠ¡ï¼Œå†å¹¶è¡Œåˆ†è§£æ¯ä¸ªå·¥åºï¼Œè¿”å›å¸¦ steps çš„å­—å…¸
    """
    global _cache_hits, _cache_misses

    # æ£€æŸ¥ç¼“å­˜
    async with _cache_lock:
        if task in _result_cache:
            _cache_hits += 1
            print(f"[ç¼“å­˜å‘½ä¸­] ä»ç¼“å­˜è¿”å›ç»“æœ: {task} (å‘½ä¸­ç‡: {_cache_hits}/{_cache_hits + _cache_misses})")
            return _result_cache[task]
        else:
            _cache_misses += 1

    print(f"[å¼€å§‹åˆ†è§£] ä»»åŠ¡: {task}")
    start_time = time.time()

    # 1) ä»»åŠ¡åˆ†è§£
    task_res = await Runner.run(agent_TaskDecomposition, input=task)
    raw_task = clean_markdown(task_res.final_output or getattr(task_res, 'content', '') or "")
    try:
        task_json = json.loads(raw_task)
    except json.JSONDecodeError:
        task_json = {"processes": []}

    # 2) å¹¶è¡Œåˆ†è§£æ‰€æœ‰å·¥åº
    procs = task_json.get("processes", [])
    if procs:
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = [decompose_single_process(proc.get("name", "")) for proc in procs]
        # å¹¶è¡Œæ‰§è¡Œ
        results = await asyncio.gather(*tasks)

        # å°†ç»“æœåˆå¹¶å›åŸæ•°æ®
        for proc, result in zip(procs, results):
            proc["steps"] = result.get("steps", [])

    end_time = time.time()
    print(f"[åˆ†è§£å®Œæˆ] æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’")

    # ç¼“å­˜ç»“æœï¼ˆä¿ç•™æœ€è¿‘10ä¸ªï¼‰
    async with _cache_lock:
        _result_cache[task] = task_json
        if len(_result_cache) > 10:
            # åˆ é™¤æœ€æ—©çš„ç¼“å­˜é¡¹
            oldest_key = next(iter(_result_cache))
            del _result_cache[oldest_key]
        print(f"[ç¼“å­˜æ›´æ–°] å½“å‰ç¼“å­˜ä»»åŠ¡æ•°: {len(_result_cache)}")

    return task_json


async def run_decompose_stream(task: str):
    """
    SSE ç‰ˆæœ¬ï¼Œä¼˜åŒ–æ¨é€ç­–ç•¥ä»¥æä¾›æ›´å¥½çš„å®æ—¶åé¦ˆ
    """

    async def event_generator():
        # 1) initial status
        yield "event: status\ndata: å·²æ¥æ”¶ä»»åŠ¡ï¼Œå¼€å§‹åˆ†è§£â€¦\n\n"

        # 2) ä»»åŠ¡åˆ†è§£
        task_res = await Runner.run(agent_TaskDecomposition, input=task)
        raw_task = clean_markdown(task_res.final_output or getattr(task_res, 'content', '') or "")
        try:
            task_json = json.loads(raw_task)
        except json.JSONDecodeError:
            task_json = {"processes": []}
        procs = task_json.get("processes", [])

        # 3) è¿›åº¦è®¡ç®—
        total = 1 + len(procs)
        step = 1
        yield f"event: progress\ndata: {int((step - 1) / total * 100)}\n\n"

        # 4) æ¨é€ä»»åŠ¡åˆ†è§£ chunk - åŒ…å«åˆå§‹å·¥åºåˆ—è¡¨ï¼ˆæ— stepsï¼‰
        yield "event: status\ndata: æ­£åœ¨è¿›è¡Œä»»åŠ¡åˆ†è§£â€¦\n\n"
        yield "event: chunk\n"
        # å‘é€åˆå§‹çš„ä»»åŠ¡JSONï¼ˆæ‰€æœ‰å·¥åºçš„stepsä¸ºç©ºæ•°ç»„ï¼‰
        for proc in procs:
            proc["steps"] = []  # ç¡®ä¿æœ‰stepså­—æ®µ
        initial_json = json.dumps(task_json, ensure_ascii=False, indent=2)
        for line in initial_json.splitlines():
            yield f"data: {line}\n"
        yield "\n"
        yield f"event: progress\ndata: {int(step / total * 100)}\n\n"

        # 5) å¹¶è¡Œåˆ†è§£æ‰€æœ‰å·¥åº
        if procs:
            yield f"event: status\ndata: æ­£åœ¨å¹¶è¡Œåˆ†è§£ {len(procs)} ä¸ªå·¥åºâ€¦\n\n"

            # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            tasks = [decompose_single_process(proc.get("name", "")) for proc in procs]

            # å¹¶è¡Œæ‰§è¡Œå¹¶è·å–ç»“æœ
            start_parallel = time.time()
            results = await asyncio.gather(*tasks)
            end_parallel = time.time()
            print(f"å¹¶è¡Œåˆ†è§£ {len(procs)} ä¸ªå·¥åºè€—æ—¶: {end_parallel - start_parallel:.2f}ç§’")

            # ä¸€æ¬¡æ€§æ›´æ–°æ‰€æœ‰å·¥åºçš„æ­¥éª¤
            for proc, result in zip(procs, results):
                proc["steps"] = result.get("steps", [])

            # æ¨é€æœ€ç»ˆçš„å®Œæ•´JSONï¼ˆåŒ…å«æ‰€æœ‰å·¥æ­¥ï¼‰
            yield f"event: status\ndata: æ‰€æœ‰å·¥åºåˆ†è§£å®Œæˆï¼Œæ­£åœ¨æ•´ç†æ•°æ®â€¦\n\n"
            yield "event: chunk\n"
            # æ¸…ç©ºä¹‹å‰çš„ç´¯ç§¯ï¼Œå‘é€ä¸€ä¸ªæ˜ç¡®çš„åˆ†éš”ç¬¦
            yield "data: ===FINAL_JSON_START===\n"
            final_json = json.dumps(task_json, ensure_ascii=False, indent=2)
            for line in final_json.splitlines():
                yield f"data: {line}\n"
            yield "data: ===FINAL_JSON_END===\n"
            yield "\n"
            yield f"event: progress\ndata: 100\n\n"

            # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿å‰ç«¯æ¥æ”¶åˆ°æ•°æ®
            await asyncio.sleep(0.5)

            # ç¼“å­˜ç»“æœ
            _result_cache[task] = task_json
            if len(_result_cache) > 5:
                oldest_key = next(iter(_result_cache))
                del _result_cache[oldest_key]

        # 6) å®Œæˆ
        yield "event: status\ndata: åˆ†è§£å®Œæˆï¼\n\n"
        yield "event: complete\ndata: ç”ŸæˆæˆåŠŸ ğŸ‰\n\n"

    return event_generator()